{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "18be42c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\minec\\miniconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\minec\\miniconda3\\lib\\site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\minec\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\minec\\miniconda3\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\minec\\miniconda3\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "e3237bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "accident_df = pd.read_csv('../accident.csv')\n",
    "#vehicle_df = pd.read_csv('../vehicle.csv')\n",
    "filtered_vehicle_df = pd.read_csv('../filtered_vehicle.csv')\n",
    "person_df = pd.read_csv('../person.csv')\n",
    "\n",
    "# merge only on 'ACCIDENT_NO' will cause a huge duplication in data, that leads to 728,905 rows of data, which by checking\n",
    "# 345,184 rows are actual duplication rows, that it  47.4%.\n",
    "\n",
    "#merged_df = pd.merge(accident_df, filtered_vehicle_df, on='ACCIDENT_NO', how='inner')\n",
    "#merged_df = pd.merge(merged_df, person_df, on='ACCIDENT_NO', how='inner')\n",
    "\n",
    "# new merge method merges on both 'ACCIDENT_NO' and 'VEHICLE_ID'\n",
    "vp = pd.merge(person_df, filtered_vehicle_df, on=['ACCIDENT_NO', 'VEHICLE_ID'], how='inner')\n",
    "merged_df = pd.merge(vp, accident_df, on='ACCIDENT_NO', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b847498",
   "metadata": {},
   "source": [
    "Lets first look at the dimension of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "9af5d187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCIDENT_NO: ['T20250000606' 'T20240012414' 'T20240001586' 'T20200004467'\n",
      " 'T20190018772']\n",
      "PERSON_ID: ['A' '01' 'B' '02' '04']\n",
      "VEHICLE_ID: ['A' 'B' 'C' 'D' 'E']\n",
      "SEX: ['M' 'F' 'U']\n",
      "AGE_GROUP: ['40-49' '26-29' '18-21' '16-17' '22-25']\n",
      "INJ_LEVEL: [3 4 2 1]\n",
      "INJ_LEVEL_DESC: ['Other injury' 'Not injured' 'Serious injury' 'Fatality']\n",
      "SEATING_POSITION: ['D' 'LF' 'OR' 'NK' 'RR']\n",
      "HELMET_BELT_WORN: [9. 1. 8. 2. 3.]\n",
      "ROAD_USER_TYPE: [2 3 9 7 1]\n",
      "ROAD_USER_TYPE_DESC: ['Drivers' 'Passengers' 'Not Known' 'Pedestrians' 'Motorcyclists']\n",
      "LICENCE_STATE: ['V' 'Z' 'O' 'W' 'D']\n",
      "TAKEN_HOSPITAL: ['N' 'Y']\n",
      "EJECTED_CODE: [0. 9. 1. 3. 2.]\n",
      "VEHICLE_YEAR_MANUF: [2016. 2008. 2012. 2009. 1994.]\n",
      "VEHICLE_DCA_CODE: [1. 2. 8. 3.]\n",
      "INITIAL_DIRECTION: ['N' 'SW' 'E' 'S' 'NE']\n",
      "ROAD_SURFACE_TYPE: [1. 9. 3. 2.]\n",
      "ROAD_SURFACE_TYPE_DESC: ['Paved' 'Not known' 'Gravel' 'Unpaved']\n",
      "REG_STATE: ['V' 'S' 'T' 'W' 'N']\n",
      "VEHICLE_BODY_STYLE: ['SEDAN' 'WAGON' 'S WAG' 'UTIL' 'DC UTE']\n",
      "VEHICLE_MAKE: ['TOYOTA' 'M MOVE' 'HOLDEN' 'HONDA' 'MAZDA']\n",
      "VEHICLE_MODEL: ['CAMRY' 'COOPER' 'KLUGER' 'VE SS' 'HILUX']\n",
      "VEHICLE_POWER: []\n",
      "VEHICLE_TYPE: [ 1  2  4 71 61]\n",
      "VEHICLE_TYPE_DESC: ['Car' 'Station Wagon' 'Utility'\n",
      " 'Light Commercial Vehicle (Rigid) <= 4.5 Tonnes GVM'\n",
      " 'Prime Mover - Single Trailer']\n",
      "VEHICLE_WEIGHT: [ 2100.  1805. 26000.  2805.  2800.]\n",
      "CONSTRUCTION_TYPE: ['R' 'P' 'A']\n",
      "FUEL_TYPE: ['M' 'P' 'D' 'G' 'E']\n",
      "NO_OF_WHEELS: [ 4.  6.  8. 12. 10.]\n",
      "NO_OF_CYLINDERS: [4. 6. 8. 5. 3.]\n",
      "SEATING_CAPACITY: [ 5.  7.  2.  3. 42.]\n",
      "TARE_WEIGHT: [1570. 1145. 1805. 1875. 1840.]\n",
      "TOTAL_NO_OCCUPANTS: [1. 2. 5. 3. 4.]\n",
      "CARRY_CAPACITY: [  530.   560. 15800.   985.  1305.]\n",
      "CUBIC_CAPACITY: [1900. 2500. 3500. 4000. 3600.]\n",
      "FINAL_DIRECTION: ['E' 'SW' 'S' 'NE' 'W']\n",
      "DRIVER_INTENT: [ 2.  1.  6. 17.  4.]\n",
      "VEHICLE_MOVEMENT: [ 2. 15.  1.  6. 17.]\n",
      "TRAILER_TYPE: ['H' 'J' 'G' 'B' 'F']\n",
      "VEHICLE_COLOUR_1: ['WHI' 'RED' 'SIL' 'BLU' 'GRY']\n",
      "VEHICLE_COLOUR_2: ['ZZ' 'OGE' 'GRY' 'SIL' 'BLK']\n",
      "CAUGHT_FIRE: [2. 9. 1. 0.]\n",
      "INITIAL_IMPACT: ['8' 'R' 'F' '1' '6']\n",
      "LAMPS: [9. 2. 1. 0.]\n",
      "LEVEL_OF_DAMAGE: [2 3 4 9 1]\n",
      "TOWED_AWAY_FLAG: [2. 1. 9.]\n",
      "TRAFFIC_CONTROL: [ 9.  0. 11.  1. 99.]\n",
      "TRAFFIC_CONTROL_DESC: ['Roundabout' 'No control' 'Giveway sign' 'Stop-go lights' 'Unknown']\n",
      "ACCIDENT_DATE: ['2023-10-23' '2024-05-15' '2024-01-21' '2020-02-24' '2019-09-23']\n",
      "ACCIDENT_TIME: ['08:40:00' '19:11:00' '17:16:00' '16:40:00' '17:34:00']\n",
      "ACCIDENT_TYPE: [1 4 8 3 2]\n",
      "ACCIDENT_TYPE_DESC: ['Collision with vehicle' 'Collision with a fixed object'\n",
      " 'No collision and no object struck' 'Struck animal' 'Struck Pedestrian']\n",
      "DAY_OF_WEEK: [2 4 1 6 3]\n",
      "DAY_WEEK_DESC: ['Monday' 'Wednesday' 'Sunday' 'Friday' 'Tuesday']\n",
      "DCA_CODE: [121 130 148 110 142]\n",
      "DCA_DESC: ['RIGHT THROUGH' 'REAR END(VEHICLES IN SAME LANE)'\n",
      " 'VEHICLE OFF FOOTPATH STRIKES VEH ON CARRIAGEWAY'\n",
      " 'CROSS TRAFFIC(INTERSECTIONS ONLY)' 'LEAVING PARKING']\n",
      "LIGHT_CONDITION: [1 3 5 2 9]\n",
      "NODE_ID: [294054 127675 797823  63183 295214]\n",
      "NO_OF_VEHICLES: [2 1 3 4 6]\n",
      "NO_PERSONS_KILLED: [0 1 2 4 3]\n",
      "NO_PERSONS_INJ_2: [0 1 3 2 4]\n",
      "NO_PERSONS_INJ_3: [1 2 0 5 3]\n",
      "NO_PERSONS_NOT_INJ: [1 5 2 0 3]\n",
      "NO_PERSONS: [2 3 6 1 5]\n",
      "POLICE_ATTEND: [2 1 9]\n",
      "ROAD_GEOMETRY: [1 5 2 4 3]\n",
      "ROAD_GEOMETRY_DESC: ['Cross intersection' 'Not at intersection' 'T intersection'\n",
      " 'Multiple intersection' 'Y intersection']\n",
      "SEVERITY: [3 2 1 4]\n",
      "SPEED_ZONE: [ 60 999  50 110 888]\n",
      "RMA: ['Local Road' 'Arterial Other' 'Arterial Highway' 'Freeway' 'Non Arterial']\n"
     ]
    }
   ],
   "source": [
    "# show some examples of each feature\n",
    "\n",
    "for col in merged_df.columns:\n",
    "    print(f\"{col}: {merged_df[col].dropna().unique()[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "ba1a85d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features\n",
    "merged_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "fe9f2925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331993"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows \n",
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "44b61e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VEHICLE_POWER             331993\n",
      "CUBIC_CAPACITY            302305\n",
      "VEHICLE_WEIGHT            282216\n",
      "CARRY_CAPACITY            282211\n",
      "TAKEN_HOSPITAL            232911\n",
      "LICENCE_STATE              75363\n",
      "EJECTED_CODE               23523\n",
      "RMA                        12720\n",
      "VEHICLE_MODEL               2591\n",
      "VEHICLE_DCA_CODE             706\n",
      "CONSTRUCTION_TYPE            669\n",
      "INITIAL_IMPACT               120\n",
      "VEHICLE_BODY_STYLE            59\n",
      "SEATING_POSITION              26\n",
      "SEX                           22\n",
      "TRAILER_TYPE                  16\n",
      "VEHICLE_YEAR_MANUF             8\n",
      "VEHICLE_COLOUR_2               2\n",
      "HELMET_BELT_WORN               1\n",
      "VEHICLE_MOVEMENT               1\n",
      "PERSON_ID                      0\n",
      "ACCIDENT_NO                    0\n",
      "VEHICLE_ID                     0\n",
      "INJ_LEVEL_DESC                 0\n",
      "INJ_LEVEL                      0\n",
      "AGE_GROUP                      0\n",
      "ROAD_SURFACE_TYPE_DESC         0\n",
      "VEHICLE_MAKE                   0\n",
      "REG_STATE                      0\n",
      "ROAD_SURFACE_TYPE              0\n",
      "VEHICLE_TYPE                   0\n",
      "NO_OF_CYLINDERS                0\n",
      "NO_OF_WHEELS                   0\n",
      "FUEL_TYPE                      0\n",
      "SEATING_CAPACITY               0\n",
      "INITIAL_DIRECTION              0\n",
      "ROAD_USER_TYPE                 0\n",
      "VEHICLE_TYPE_DESC              0\n",
      "ROAD_USER_TYPE_DESC            0\n",
      "DRIVER_INTENT                  0\n",
      "FINAL_DIRECTION                0\n",
      "TARE_WEIGHT                    0\n",
      "TOTAL_NO_OCCUPANTS             0\n",
      "CAUGHT_FIRE                    0\n",
      "LAMPS                          0\n",
      "LEVEL_OF_DAMAGE                0\n",
      "VEHICLE_COLOUR_1               0\n",
      "TRAFFIC_CONTROL                0\n",
      "TRAFFIC_CONTROL_DESC           0\n",
      "ACCIDENT_DATE                  0\n",
      "ACCIDENT_TIME                  0\n",
      "ACCIDENT_TYPE                  0\n",
      "ACCIDENT_TYPE_DESC             0\n",
      "DAY_OF_WEEK                    0\n",
      "TOWED_AWAY_FLAG                0\n",
      "DAY_WEEK_DESC                  0\n",
      "DCA_CODE                       0\n",
      "LIGHT_CONDITION                0\n",
      "DCA_DESC                       0\n",
      "NO_OF_VEHICLES                 0\n",
      "NO_PERSONS_KILLED              0\n",
      "NO_PERSONS_INJ_2               0\n",
      "NODE_ID                        0\n",
      "NO_PERSONS_INJ_3               0\n",
      "NO_PERSONS_NOT_INJ             0\n",
      "POLICE_ATTEND                  0\n",
      "NO_PERSONS                     0\n",
      "ROAD_GEOMETRY                  0\n",
      "ROAD_GEOMETRY_DESC             0\n",
      "SEVERITY                       0\n",
      "SPEED_ZONE                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if there is any null value\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(merged_df.isnull().sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc1dec",
   "metadata": {},
   "source": [
    "continue process the data, check if there is any uneccessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "0b8cea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these features are considered to be useless with respect with training models\n",
    "drop_feature = ['ACCIDENT_NO',\n",
    "                'NODE_ID', \n",
    "                'PERSON_ID',\n",
    "                'VEHICLE_ID',\n",
    "                'ACCIDENT_TIME',\n",
    "                'VEHICLE_MODEL',\n",
    "                'VEHICLE_MAKE',\n",
    "                'VEHICLE_BODY_STYLE',\n",
    "                'DCA_CODE'\n",
    "                ]\n",
    "merged_df = merged_df.drop(columns=drop_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "8b6bb7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX                          3\n",
      "AGE_GROUP                   14\n",
      "INJ_LEVEL                    4\n",
      "INJ_LEVEL_DESC               4\n",
      "SEATING_POSITION             9\n",
      "HELMET_BELT_WORN             9\n",
      "ROAD_USER_TYPE               8\n",
      "ROAD_USER_TYPE_DESC          6\n",
      "LICENCE_STATE               11\n",
      "TAKEN_HOSPITAL               2\n",
      "EJECTED_CODE                 5\n",
      "VEHICLE_YEAR_MANUF          64\n",
      "VEHICLE_DCA_CODE             4\n",
      "INITIAL_DIRECTION            9\n",
      "ROAD_SURFACE_TYPE            4\n",
      "ROAD_SURFACE_TYPE_DESC       4\n",
      "REG_STATE                    7\n",
      "VEHICLE_POWER                0\n",
      "VEHICLE_TYPE                22\n",
      "VEHICLE_TYPE_DESC           22\n",
      "VEHICLE_WEIGHT            1208\n",
      "CONSTRUCTION_TYPE            3\n",
      "FUEL_TYPE                    8\n",
      "NO_OF_WHEELS                10\n",
      "NO_OF_CYLINDERS             24\n",
      "SEATING_CAPACITY            61\n",
      "TARE_WEIGHT               3676\n",
      "TOTAL_NO_OCCUPANTS          40\n",
      "CARRY_CAPACITY            3201\n",
      "CUBIC_CAPACITY              99\n",
      "FINAL_DIRECTION              9\n",
      "DRIVER_INTENT               20\n",
      "VEHICLE_MOVEMENT            20\n",
      "TRAILER_TYPE                12\n",
      "VEHICLE_COLOUR_1            18\n",
      "VEHICLE_COLOUR_2            17\n",
      "CAUGHT_FIRE                  4\n",
      "INITIAL_IMPACT              17\n",
      "LAMPS                        4\n",
      "LEVEL_OF_DAMAGE              7\n",
      "TOWED_AWAY_FLAG              3\n",
      "TRAFFIC_CONTROL             17\n",
      "TRAFFIC_CONTROL_DESC        17\n",
      "ACCIDENT_DATE             4565\n",
      "ACCIDENT_TYPE                9\n",
      "ACCIDENT_TYPE_DESC           9\n",
      "DAY_OF_WEEK                  8\n",
      "DAY_WEEK_DESC                7\n",
      "DCA_DESC                    81\n",
      "LIGHT_CONDITION              7\n",
      "NO_OF_VEHICLES              17\n",
      "NO_PERSONS_KILLED            6\n",
      "NO_PERSONS_INJ_2            13\n",
      "NO_PERSONS_INJ_3            23\n",
      "NO_PERSONS_NOT_INJ          39\n",
      "NO_PERSONS                  45\n",
      "POLICE_ATTEND                3\n",
      "ROAD_GEOMETRY                9\n",
      "ROAD_GEOMETRY_DESC           9\n",
      "SEVERITY                     4\n",
      "SPEED_ZONE                  13\n",
      "RMA                          5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# lets see if theres some features that is categorical\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(merged_df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1c8b2",
   "metadata": {},
   "source": [
    "it seems that there are some features that worth using one-hot to catagorise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc741c2a",
   "metadata": {},
   "source": [
    "first, there are some duplicated data that pairs with their description. to one hot these data, i will drop the desc features and keep others, since they represents the same thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "d8c054b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_and_report_desc_fields(df):\n",
    "    desc_cols = [col for col in df.columns if col.endswith('_DESC')]\n",
    "    for col in desc_cols:\n",
    "        print(f\" - {col}\")\n",
    "    return df.drop(columns=desc_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "938975df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - INJ_LEVEL_DESC\n",
      " - ROAD_USER_TYPE_DESC\n",
      " - ROAD_SURFACE_TYPE_DESC\n",
      " - VEHICLE_TYPE_DESC\n",
      " - TRAFFIC_CONTROL_DESC\n",
      " - ACCIDENT_TYPE_DESC\n",
      " - DAY_WEEK_DESC\n",
      " - DCA_DESC\n",
      " - ROAD_GEOMETRY_DESC\n"
     ]
    }
   ],
   "source": [
    "merged_df = drop_and_report_desc_fields(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "b80c8d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX: ['M' 'F' 'U']\n",
      "AGE_GROUP: ['40-49' '26-29' '18-21' '16-17' '22-25']\n",
      "INJ_LEVEL: [3 4 2 1]\n",
      "SEATING_POSITION: ['D' 'LF' 'OR' 'NK' 'RR']\n",
      "HELMET_BELT_WORN: [9. 1. 8. 2. 3.]\n",
      "ROAD_USER_TYPE: [2 3 9 7 1]\n",
      "LICENCE_STATE: ['V' 'Z' 'O' 'W' 'D']\n",
      "TAKEN_HOSPITAL: ['N' 'Y']\n",
      "EJECTED_CODE: [0. 9. 1. 3. 2.]\n",
      "VEHICLE_YEAR_MANUF: [2016. 2008. 2012. 2009. 1994.]\n",
      "VEHICLE_DCA_CODE: [1. 2. 8. 3.]\n",
      "INITIAL_DIRECTION: ['N' 'SW' 'E' 'S' 'NE']\n",
      "ROAD_SURFACE_TYPE: [1. 9. 3. 2.]\n",
      "REG_STATE: ['V' 'S' 'T' 'W' 'N']\n",
      "VEHICLE_POWER: []\n",
      "VEHICLE_TYPE: [ 1  2  4 71 61]\n",
      "VEHICLE_WEIGHT: [ 2100.  1805. 26000.  2805.  2800.]\n",
      "CONSTRUCTION_TYPE: ['R' 'P' 'A']\n",
      "FUEL_TYPE: ['M' 'P' 'D' 'G' 'E']\n",
      "NO_OF_WHEELS: [ 4.  6.  8. 12. 10.]\n",
      "NO_OF_CYLINDERS: [4. 6. 8. 5. 3.]\n",
      "SEATING_CAPACITY: [ 5.  7.  2.  3. 42.]\n",
      "TARE_WEIGHT: [1570. 1145. 1805. 1875. 1840.]\n",
      "TOTAL_NO_OCCUPANTS: [1. 2. 5. 3. 4.]\n",
      "CARRY_CAPACITY: [  530.   560. 15800.   985.  1305.]\n",
      "CUBIC_CAPACITY: [1900. 2500. 3500. 4000. 3600.]\n",
      "FINAL_DIRECTION: ['E' 'SW' 'S' 'NE' 'W']\n",
      "DRIVER_INTENT: [ 2.  1.  6. 17.  4.]\n",
      "VEHICLE_MOVEMENT: [ 2. 15.  1.  6. 17.]\n",
      "TRAILER_TYPE: ['H' 'J' 'G' 'B' 'F']\n",
      "VEHICLE_COLOUR_1: ['WHI' 'RED' 'SIL' 'BLU' 'GRY']\n",
      "VEHICLE_COLOUR_2: ['ZZ' 'OGE' 'GRY' 'SIL' 'BLK']\n",
      "CAUGHT_FIRE: [2. 9. 1. 0.]\n",
      "INITIAL_IMPACT: ['8' 'R' 'F' '1' '6']\n",
      "LAMPS: [9. 2. 1. 0.]\n",
      "LEVEL_OF_DAMAGE: [2 3 4 9 1]\n",
      "TOWED_AWAY_FLAG: [2. 1. 9.]\n",
      "TRAFFIC_CONTROL: [ 9.  0. 11.  1. 99.]\n",
      "ACCIDENT_DATE: ['2023-10-23' '2024-05-15' '2024-01-21' '2020-02-24' '2019-09-23']\n",
      "ACCIDENT_TYPE: [1 4 8 3 2]\n",
      "DAY_OF_WEEK: [2 4 1 6 3]\n",
      "LIGHT_CONDITION: [1 3 5 2 9]\n",
      "NO_OF_VEHICLES: [2 1 3 4 6]\n",
      "NO_PERSONS_KILLED: [0 1 2 4 3]\n",
      "NO_PERSONS_INJ_2: [0 1 3 2 4]\n",
      "NO_PERSONS_INJ_3: [1 2 0 5 3]\n",
      "NO_PERSONS_NOT_INJ: [1 5 2 0 3]\n",
      "NO_PERSONS: [2 3 6 1 5]\n",
      "POLICE_ATTEND: [2 1 9]\n",
      "ROAD_GEOMETRY: [1 5 2 4 3]\n",
      "SEVERITY: [3 2 1 4]\n",
      "SPEED_ZONE: [ 60 999  50 110 888]\n",
      "RMA: ['Local Road' 'Arterial Other' 'Arterial Highway' 'Freeway' 'Non Arterial']\n"
     ]
    }
   ],
   "source": [
    "# checking the new demsion of the cleaned df\n",
    "for col in merged_df.columns:\n",
    "    print(f\"{col}: {merged_df[col].dropna().unique()[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c54683",
   "metadata": {},
   "source": [
    "Create a new feature, vehicle age = accident date - year of manufacture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "16e2b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"ACCIDENT_DATE\"] = pd.to_datetime(merged_df[\"ACCIDENT_DATE\"], errors='coerce')\n",
    "\n",
    "merged_df[\"ACCIDENT_YEAR\"] = merged_df[\"ACCIDENT_DATE\"].dt.year\n",
    "\n",
    "merged_df[\"VEHICLE_AGE\"] = merged_df[\"ACCIDENT_YEAR\"] - merged_df[\"VEHICLE_YEAR_MANUF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "23ead79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feature = ['VEHICLE_YEAR_MANUF',\n",
    "                'ACCIDENT_DATE',\n",
    "                'ACCIDENT_YEAR'\n",
    "                ]\n",
    "cleaned_df = merged_df.drop(columns=drop_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "242343cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "cbd415bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331993"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c506df1",
   "metadata": {},
   "source": [
    "before one hot, i will keep a version of df for light GBM,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "b2e28d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv('../merged_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "b1b26351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef one_hot_encode_expand(df, columns_to_encode, drop_first=True):\\n    df_encoded = pd.get_dummies(df, columns=columns_to_encode, drop_first=drop_first)\\n    return df_encoded\\n'"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def one_hot_encode_expand(df, columns_to_encode, drop_first=True):\n",
    "    df_encoded = pd.get_dummies(df, columns=columns_to_encode, drop_first=drop_first)\n",
    "    return df_encoded\n",
    "'''\n",
    "# not suitable to expand the one hot encode, it will cause dimension expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "59229fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_vectorise(df, columns):\n",
    "    df_new = df.drop(columns=columns).copy()\n",
    "\n",
    "    for col in columns:\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        encoded = encoder.fit_transform(df[[col]])\n",
    "        # save as list \n",
    "        encoded_vectors = pd.Series(list(encoded), index=df.index)\n",
    "        # name the new features as col + '_vec'\n",
    "        df_new[col + '_vec'] = encoded_vectors\n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "7e03d7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX                      3\n",
      "AGE_GROUP               14\n",
      "INJ_LEVEL                4\n",
      "SEATING_POSITION         9\n",
      "HELMET_BELT_WORN         9\n",
      "ROAD_USER_TYPE           8\n",
      "LICENCE_STATE           11\n",
      "TAKEN_HOSPITAL           2\n",
      "EJECTED_CODE             5\n",
      "VEHICLE_DCA_CODE         4\n",
      "INITIAL_DIRECTION        9\n",
      "ROAD_SURFACE_TYPE        4\n",
      "REG_STATE                7\n",
      "VEHICLE_POWER            0\n",
      "VEHICLE_TYPE            22\n",
      "VEHICLE_WEIGHT        1208\n",
      "CONSTRUCTION_TYPE        3\n",
      "FUEL_TYPE                8\n",
      "NO_OF_WHEELS            10\n",
      "NO_OF_CYLINDERS         24\n",
      "SEATING_CAPACITY        61\n",
      "TARE_WEIGHT           3676\n",
      "TOTAL_NO_OCCUPANTS      40\n",
      "CARRY_CAPACITY        3201\n",
      "CUBIC_CAPACITY          99\n",
      "FINAL_DIRECTION          9\n",
      "DRIVER_INTENT           20\n",
      "VEHICLE_MOVEMENT        20\n",
      "TRAILER_TYPE            12\n",
      "VEHICLE_COLOUR_1        18\n",
      "VEHICLE_COLOUR_2        17\n",
      "CAUGHT_FIRE              4\n",
      "INITIAL_IMPACT          17\n",
      "LAMPS                    4\n",
      "LEVEL_OF_DAMAGE          7\n",
      "TOWED_AWAY_FLAG          3\n",
      "TRAFFIC_CONTROL         17\n",
      "ACCIDENT_TYPE            9\n",
      "DAY_OF_WEEK              8\n",
      "LIGHT_CONDITION          7\n",
      "NO_OF_VEHICLES          17\n",
      "NO_PERSONS_KILLED        6\n",
      "NO_PERSONS_INJ_2        13\n",
      "NO_PERSONS_INJ_3        23\n",
      "NO_PERSONS_NOT_INJ      39\n",
      "NO_PERSONS              45\n",
      "POLICE_ATTEND            3\n",
      "ROAD_GEOMETRY            9\n",
      "SEVERITY                 4\n",
      "SPEED_ZONE              13\n",
      "RMA                      5\n",
      "VEHICLE_AGE             61\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# lets see if theres some features that is categorical\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(cleaned_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "b70e2ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_columns = [\n",
    "    'SEX', 'AGE_GROUP', 'INJ_LEVEL', 'SEATING_POSITION', 'HELMET_BELT_WORN',\n",
    "    'ROAD_USER_TYPE', 'LICENCE_STATE', 'TAKEN_HOSPITAL', 'EJECTED_CODE',\n",
    "    'VEHICLE_DCA_CODE', 'INITIAL_DIRECTION', 'ROAD_SURFACE_TYPE',\n",
    "    'REG_STATE', 'VEHICLE_TYPE', 'CONSTRUCTION_TYPE',\n",
    "    'FUEL_TYPE', 'FINAL_DIRECTION', 'TRAILER_TYPE', 'VEHICLE_COLOUR_1',\n",
    "    'VEHICLE_COLOUR_2', 'INITIAL_IMPACT', 'LEVEL_OF_DAMAGE', 'TOWED_AWAY_FLAG',\n",
    "    'TRAFFIC_CONTROL', 'ACCIDENT_TYPE', 'DAY_OF_WEEK',\n",
    "    'LIGHT_CONDITION', 'POLICE_ATTEND', 'ROAD_GEOMETRY', 'RMA'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "38af421d",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 35.5 MiB for an array with shape (14, 331993) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[517]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# each one hot one hot category is encoded as a new feature, as result, there is 518 features\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# merged_df_onehot_expand_df = one_hot_encode_expand(desc_cleaned_merged_df, one_hot_columns)\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# vectorised one hot df, still 56 features, ready for neuron networking\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m merged_onehot_df = \u001b[43mone_hot_encode_vectorise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_hot_columns\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[513]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mone_hot_encode_vectorise\u001b[39m\u001b[34m(df, columns)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mone_hot_encode_vectorise\u001b[39m(df, columns):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     df_new = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[32m      5\u001b[39m         encoder = OneHotEncoder(sparse_output=\u001b[38;5;28;01mFalse\u001b[39;00m, handle_unknown=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6811\u001b[39m, in \u001b[36mNDFrame.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m   6662\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   6663\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> Self:\n\u001b[32m   6664\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   6665\u001b[39m \u001b[33;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[32m   6666\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   6809\u001b[39m \u001b[33;03m    dtype: int64\u001b[39;00m\n\u001b[32m   6810\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6811\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6812\u001b[39m     \u001b[38;5;28mself\u001b[39m._clear_item_cache()\n\u001b[32m   6813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(data, axes=data.axes).__finalize__(\n\u001b[32m   6814\u001b[39m         \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mcopy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6815\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:604\u001b[39m, in \u001b[36mBaseBlockManager.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m    601\u001b[39m         res._blklocs = \u001b[38;5;28mself\u001b[39m._blklocs.copy()\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[39m, in \u001b[36mBlockManager._consolidate_inplace\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1783\u001b[39m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[32m   1784\u001b[39m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[32m   1785\u001b[39m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[32m   1786\u001b[39m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[32m   1787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_consolidated():\n\u001b[32m-> \u001b[39m\u001b[32m1788\u001b[39m         \u001b[38;5;28mself\u001b[39m.blocks = \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m         \u001b[38;5;28mself\u001b[39m._is_consolidated = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1790\u001b[39m         \u001b[38;5;28mself\u001b[39m._known_consolidated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[39m, in \u001b[36m_consolidate\u001b[39m\u001b[34m(blocks)\u001b[39m\n\u001b[32m   2267\u001b[39m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] = []\n\u001b[32m   2268\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[32m-> \u001b[39m\u001b[32m2269\u001b[39m     merged_blocks, _ = \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2270\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[32m   2271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2272\u001b[39m     new_blocks = extend_blocks(merged_blocks, new_blocks)\n\u001b[32m   2273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2301\u001b[39m, in \u001b[36m_merge_blocks\u001b[39m\u001b[34m(blocks, dtype, can_consolidate)\u001b[39m\n\u001b[32m   2298\u001b[39m     new_values = bvals2[\u001b[32m0\u001b[39m]._concat_same_type(bvals2, axis=\u001b[32m0\u001b[39m)\n\u001b[32m   2300\u001b[39m argsort = np.argsort(new_mgr_locs)\n\u001b[32m-> \u001b[39m\u001b[32m2301\u001b[39m new_values = \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   2302\u001b[39m new_mgr_locs = new_mgr_locs[argsort]\n\u001b[32m   2304\u001b[39m bp = BlockPlacement(new_mgr_locs)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 35.5 MiB for an array with shape (14, 331993) and data type float64"
     ]
    }
   ],
   "source": [
    "# each one hot one hot category is encoded as a new feature, as result, there is 518 features\n",
    "# merged_df_onehot_expand_df = one_hot_encode_expand(desc_cleaned_merged_df, one_hot_columns)\n",
    "\n",
    "# vectorised one hot df, still 56 features, ready for neuron networking\n",
    "merged_onehot_df = one_hot_encode_vectorise(cleaned_df, one_hot_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18354586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331993"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_onehot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b6a55",
   "metadata": {},
   "source": [
    "Now, since MLP is very sensitive to N/A values and range of the data, i will fill N/A and normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5089aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_summary(df):\n",
    "    total = df.isnull().sum()\n",
    "    percent = (total / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({'Missing Count': total, 'Missing Percentage': percent})\n",
    "    missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "    missing_df = missing_df.sort_values(by='Missing Percentage', ascending=False)\n",
    "    return missing_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe584b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Missing Count  Missing Percentage\n",
      "VEHICLE_POWER              331993          100.000000\n",
      "CUBIC_CAPACITY             302305           91.057643\n",
      "VEHICLE_WEIGHT             282216           85.006612\n",
      "CARRY_CAPACITY             282211           85.005106\n",
      "VEHICLE_BODY_STYLE             59            0.017771\n",
      "VEHICLE_AGE                     8            0.002410\n",
      "VEHICLE_MOVEMENT                1            0.000301\n"
     ]
    }
   ],
   "source": [
    "missing_report = missing_value_summary(merged_onehot_df)\n",
    "print(missing_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c36e13",
   "metadata": {},
   "source": [
    "wow, a very high percentage of some of theses data are missing, then it is necessary to drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_onehot_df = merged_onehot_df.drop(columns=[\"VEHICLE_POWER\", \"CUBIC_CAPACITY\", \"VEHICLE_WEIGHT\", \"CARRY_CAPACITY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddaad50",
   "metadata": {},
   "source": [
    "for the other 2, lemme just fill in median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b960ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"VEHICLE_MOVEMENT\"]:\n",
    "    median_val = merged_onehot_df[col].median()\n",
    "    merged_onehot_df[col] = merged_onehot_df[col].fillna(median_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660bb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 找出所有 one-hot 列（以 \"_vec\" 结尾）\n",
    "one_hot_columns = [col for col in merged_onehot_df.columns if col.endswith('_vec')]\n",
    "\n",
    "# 2. 排除 one-hot 和标签列，剩下的都是要归一化的连续数值列\n",
    "non_onehot_cols = [col for col in merged_onehot_df.columns if col not in one_hot_columns + ['SEVERITY']]\n",
    "\n",
    "len(non_onehot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dec3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331993"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_onehot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa815602",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'SEDAN'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_7624\\2272771413.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m scaler = StandardScaler()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m merged_onehot_df[non_onehot_cols] = scaler.fit_transform(merged_onehot_df[non_onehot_cols])\n",
      "\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m     @wraps(f)\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    321\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m             return_tuple = (\n",
      "\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    914\u001b[39m                 )\n\u001b[32m    915\u001b[39m \n\u001b[32m    916\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    890\u001b[39m             Fitted scaler.\n\u001b[32m    891\u001b[39m         \"\"\"\n\u001b[32m    892\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    893\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1385\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m                 )\n\u001b[32m   1388\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    926\u001b[39m         self : object\n\u001b[32m    927\u001b[39m             Fitted scaler.\n\u001b[32m    928\u001b[39m         \"\"\"\n\u001b[32m    929\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         X = validate_data(\n\u001b[32m    931\u001b[39m             self,\n\u001b[32m    932\u001b[39m             X,\n\u001b[32m    933\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2940\u001b[39m             out = y\n\u001b[32m   2941\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2942\u001b[39m             out = X, y\n\u001b[32m   2943\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2945\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2947\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1052\u001b[39m                         )\n\u001b[32m   1053\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1055\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m                 raise ValueError(\n\u001b[32m   1058\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    835\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    836\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    837\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    840\u001b[39m \n\u001b[32m    841\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2149\u001b[39m     def __array__(\n\u001b[32m   2150\u001b[39m         self, dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2151\u001b[39m     ) -> np.ndarray:\n\u001b[32m   2152\u001b[39m         values = self._values\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m         arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2154\u001b[39m         if (\n\u001b[32m   2155\u001b[39m             astype_is_view(values.dtype, arr.dtype)\n\u001b[32m   2156\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'SEDAN'"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "merged_onehot_df[non_onehot_cols] = scaler.fit_transform(merged_onehot_df[non_onehot_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "347fbc2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[461]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmerged_onehot_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../merged_onehot.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3956\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3958\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m     frame=df,\n\u001b[32m   3960\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m     decimal=decimal,\n\u001b[32m   3965\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3972\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:270\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28mself\u001b[39m.filepath_or_buffer,\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:275\u001b[39m, in \u001b[36mCSVFormatter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._need_to_save_header:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_header()\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[39m, in \u001b[36mCSVFormatter._save_body\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start_i >= end_i:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minec\\miniconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:324\u001b[39m, in \u001b[36mCSVFormatter._save_chunk\u001b[39m\u001b[34m(self, start_i, end_i)\u001b[39m\n\u001b[32m    321\u001b[39m data = \u001b[38;5;28mlist\u001b[39m(res._iter_column_arrays())\n\u001b[32m    323\u001b[39m ix = \u001b[38;5;28mself\u001b[39m.data_index[slicer]._get_values_for_csv(**\u001b[38;5;28mself\u001b[39m._number_format)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[43mlibwriters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mwriters.pyx:73\u001b[39m, in \u001b[36mpandas._libs.writers.write_csv_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "merged_onehot_df.to_csv('../merged_onehot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d56969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
